# -*- coding: utf-8 -*-
"""Nohesh Multimodal Fake news detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AfVwZV_1xmSjzVgK_S1oZEWdlne6P42T
"""

import numpy as np
import pandas as pd

import os
import urllib.request
import sys

from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as f
import torch.optim as optim

import torchvision
from torchvision.transforms import v2
from torchvision import models
from torchvision.models import resnet50, ResNet50_Weights
import torch.optim.lr_scheduler as lr_scheduler

import random
from PIL import Image
import matplotlib.pyplot as plt

if torch.cuda.is_available():
    device = torch.device('cuda')
    print("CUDA is available. Using GPU.")
else:
    device = torch.device('cpu')
    print("CUDA is not available. Using CPU.")

df = pd.read_csv('/content/drive/MyDrive/multimodal_only_samples/multimodal_train.tsv', sep='\t')

df.drop(['2_way_label', '3_way_label', 'title'], axis = 1, inplace =True)

df, df_backup = train_test_split(
    df,
    test_size=0.95,
    shuffle=True,
    stratify=df["6_way_label"]
)

df.reset_index(drop=True, inplace=True)
df

print(df['clean_title'].isnull().sum())
print(df['id'].isnull().sum())
print(df['hasImage'].isnull().sum())
print(df['hasImage'].value_counts())

import matplotlib.pyplot as plt

# Calculate text lengths
df["title_length"] = df["clean_title"].apply(lambda x: len(x.split()))

plt.figure(figsize=(8,5))
plt.hist(df["title_length"], bins=30, edgecolor="black", alpha=0.7)

plt.xlabel("Number of Words in News Title")
plt.ylabel("Frequency")
plt.title("Distribution of News Title Lengths in Fakeddit Dataset")

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,5))
sns.countplot(
    x="6_way_label",
    data=df,
    palette="Set2"
)

plt.xlabel("Fake News Class Label")
plt.ylabel("Number of Samples")
plt.title("Class Distribution in Fakeddit Dataset")

plt.tight_layout()
plt.show()

"""Based on the class distribution graph, i will say that the classes are not represented equally in the dataset.

Due to this, I applied balanced class weights later on in my loss function
"""

import os
import numpy as np
from urllib import request
import time

df = df.replace(np.nan, '', regex=True)
df.fillna('', inplace=True)

SAVE_DIR = "/content/drive/MyDrive/multimodal_only_images"
os.makedirs(SAVE_DIR, exist_ok=True)

MAX_IMAGES = 3000
downloaded = 0

start_time = time.time()

for index, row in df.iterrows():
    if downloaded >= MAX_IMAGES:
        break

    if row.get("hasImage") == True and row.get("image_url") not in ["", "nan"]:
        image_url = row["image_url"]
        image_id = str(row["id"])
        path = os.path.join(SAVE_DIR, image_id + ".jpg")

        try:
            request.urlretrieve(image_url, path)
            downloaded += 1

            if downloaded % 50 == 0:
                print(f"Downloaded {downloaded} images")

        except:
            continue

    if time.time() - start_time > 3000:
        print("Time limit reached (5 minutes)")
        break

print(f"Finished downloading {downloaded} images")

import os
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

IMAGE_DIR = "/content/drive/MyDrive/multimodal_only_images"

shown = 0

for _, row in df.iterrows():
    image_path = os.path.join(IMAGE_DIR, str(row["id"]) + ".jpg")

    if os.path.exists(image_path):
        img = Image.open(image_path).convert("RGB")
        img_np = np.array(img)

        print("Image shape (H, W, C):", img_np.shape)

        plt.figure(figsize=(3,3))
        plt.imshow(img_np)
        plt.title(f"Size: {img_np.shape}")
        plt.axis("off")
        plt.show()

        shown += 1
        if shown == 5:
            break

import os
import matplotlib.pyplot as plt
from PIL import Image

IMAGE_DIR = "/content/drive/MyDrive/multimodal_only_images"

image_id = str(df["id"].iloc[0])
image_path = os.path.join(IMAGE_DIR, image_id + ".jpg")

if os.path.exists(image_path):
    image = Image.open(image_path).convert("RGB")

    r, g, b = image.split()

    plt.figure(figsize=(10, 4))

    plt.subplot(1, 3, 1)
    plt.imshow(r, cmap="Reds")
    plt.title("Red Channel")
    plt.axis("off")

    plt.subplot(1, 3, 2)
    plt.imshow(g, cmap="Greens")
    plt.title("Green Channel")
    plt.axis("off")

    plt.subplot(1, 3, 3)
    plt.imshow(b, cmap="Blues")
    plt.title("Blue Channel")
    plt.axis("off")

    plt.tight_layout()
    plt.show()
else:
    print("Image file not found:", image_path)

import os
from PIL import Image

def validate_images(df, image_dir):
    corrupted_ids = []

    for _, row in df.iterrows():
        image_path = os.path.join(image_dir, str(row["id"]) + ".jpg")

        if not os.path.exists(image_path):
            corrupted_ids.append(row["id"])
            continue

        try:
            with Image.open(image_path) as img:
                img.verify()
        except Exception as e:
            print(f"Corrupted image: {image_path} | Error: {e}")
            corrupted_ids.append(row["id"])

    return corrupted_ids


IMAGE_DIR = "/content/drive/MyDrive/multimodal_only_images"

print("Clean dataframe size:", df.shape)

import os
from PIL import Image
from torchvision.transforms import v2

IMAGE_DIR = "/content/drive/MyDrive/multimodal_only_images"
resize_transform = v2.Resize((256, 256))

resized = 0
skipped = 0

for _, row in df.iterrows():
    image_path = os.path.join(IMAGE_DIR, str(row["id"]) + ".jpg")

    if not os.path.exists(image_path):
        skipped += 1
        continue

    try:
        image = Image.open(image_path).convert("RGB")
        resized_image = resize_transform(image)
        resized_image.save(image_path)
        resized += 1
    except Exception as e:
        skipped += 1
        continue

print(f"Resized images: {resized}")
print(f"Skipped images (missing/corrupt): {skipped}")

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

IMAGE_DIR = "/content/drive/MyDrive/multimodal_only_images"

shown = 0
i = 0

while shown < 5 and i < len(df):
    image_path = os.path.join(IMAGE_DIR, str(df["id"].iloc[i]) + ".jpg")

    if os.path.exists(image_path):
        im = np.array(Image.open(image_path).convert("RGB"))

        print("Image shape:", im.shape)

        plt.figure(figsize=(4,4))
        plt.imshow(im)
        plt.axis("off")
        plt.show()

        shown += 1

    i += 1

! pip install bert-serving-server
! pip install bert-serving-client
! pip install torch transformers

import torch
from transformers import BertModel, BertTokenizer

model_name = 'bert-base-uncased'
tokenizer = BertTokenizer.from_pretrained(model_name)
bert_model = BertModel.from_pretrained(model_name, output_hidden_states = True)

bert_model.eval()

def get_bert_embedding(text):
    inputs = tokenizer.encode_plus(text, add_special_tokens = True, return_tensors='pt', max_length=80, truncation=True, padding='max_length')

    return inputs['input_ids'].squeeze(0), inputs['attention_mask'].squeeze(0)

text = "This is an example Reddit submission title."
input_ids, attention_mask = get_bert_embedding(text)
print(input_ids.shape)
print(attention_mask.shape)

from sklearn.model_selection import train_test_split
df_train, df_test = train_test_split(df, test_size=0.2, stratify=df["6_way_label"])
df_test, df_val = train_test_split(df_test, test_size=0.5, stratify=df_test["6_way_label"])

import os
import torch
from torch.utils.data import Dataset
from torchvision.transforms import v2
from PIL import Image

class FakedditDataset(Dataset):
    def __init__(self, df, text_field="clean_title", label_field="6_way_label", image_id="id"):
        self.df = df.reset_index(drop=True)
        self.text_field = text_field
        self.label_field = label_field
        self.image_id = image_id

        self.image_dir = "/content/drive/MyDrive/multimodal_only_images"

        self.mean = [0.485, 0.456, 0.406]
        self.std = [0.229, 0.224, 0.225]

        self.transform_func = v2.Compose([
            v2.Resize((256, 256)),
            v2.ToImage(),
            v2.ToDtype(torch.float32, scale=True),
            v2.Normalize(self.mean, self.std)
        ])

        self.fallback_image = Image.new("RGB", (256, 256), (0, 0, 0))

    def __getitem__(self, index):
        text = str(self.df.at[index, self.text_field])
        label = torch.tensor(self.df.at[index, self.label_field], dtype=torch.long)

        img_name = str(self.df.at[index, self.image_id]) + ".jpg"
        img_path = os.path.join(self.image_dir, img_name)

        if os.path.exists(img_path):
            image = Image.open(img_path).convert("RGB")
        else:
            image = self.fallback_image

        img = self.transform_func(image)

        input_ids, attention_mask = get_bert_embedding(text)

        return input_ids, attention_mask, label, img

    def __len__(self):
        return len(self.df)

train_dataset = FakedditDataset(df_train)
val_dataset = FakedditDataset(df_val)
test_dataset = FakedditDataset(df_test)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

input_ids, attention_mask, label, img = next(iter(train_loader))
print(input_ids.shape, attention_mask.shape, label.shape, img.shape)

class MultimodalClassifier(nn.Module):
    def __init__(self, num_classes=6):

        super(MultimodalClassifier, self).__init__()

        self.num_classes = num_classes

        self.image_conv = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )

        self.image_fc = nn.Sequential(
            nn.Linear(128 * 32 * 32, num_classes),
            nn.ReLU()
        )

        self.drop = nn.Dropout(p=0.3)

        self.text_model = BertModel.from_pretrained("bert-base-uncased")
        self.fc_text = nn.Linear(in_features=self.text_model.config.hidden_size, out_features=num_classes, bias=True)

        self.softmax = nn.Softmax(dim=1)

    def forward(self, image, text_input_ids, text_attention_mask,):

        x_img = self.image_conv(image)
        x_img = x_img.view(x_img.size(0), -1)
        x_img = self.image_fc(x_img)
        x_img = self.drop(x_img)

        x_text_last_hidden_states = self.text_model(
            input_ids = text_input_ids,
            attention_mask = text_attention_mask,
            return_dict=False
        )
        x_text_pooled_output = x_text_last_hidden_states[0][:, 0, :]
        x_text = self.fc_text(x_text_pooled_output)
        x_text = self.drop(x_text)

        x = torch.max(x_text, x_img)

        return x

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = MultimodalClassifier(num_classes=6)
model= model.to(device)

class EarlyStopping:
    def __init__(self, patience=4, verbose=False, delta=0):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_loss = None
        self.early_stop = False
        self.delta = delta

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss + self.delta:
            self.counter += 1
            if self.verbose:
                print(f"EarlyStopping counter: {self.counter} out of {self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

labels = df_train['6_way_label'].to_numpy()

import torch
import torch.nn as nn
import numpy as np
from sklearn.utils.class_weight import compute_class_weight
from torch.optim import lr_scheduler
model = model.to(device)

class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(labels),
    y=labels
)
class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)

criterion = nn.CrossEntropyLoss(weight=class_weights)
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)

scheduler = lr_scheduler.ReduceLROnPlateau(
    optimizer,
    factor=0.5,
    patience=1,
    min_lr=1e-6
)

num_epochs = 20

class EarlyStopping:
    def __init__(self, patience=5):
        self.patience = patience
        self.counter = 0
        self.best_loss = None
        self.early_stop = False

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0


# Training function
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):
    early_stopping = EarlyStopping(patience=5)

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for input_ids, attention_mask, label, img in train_loader:
            input_ids = input_ids.to(device)
            attention_mask = attention_mask.to(device)
            label = label.to(device)
            img = img.to(device)

            optimizer.zero_grad()
            outputs = model(img, input_ids, attention_mask)
            loss = criterion(outputs, label)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * img.size(0)

        train_loss = running_loss / len(train_loader.dataset)

        model.eval()
        val_loss = 0.0
        correct = 0

        with torch.no_grad():
            for input_ids, attention_mask, label, img in val_loader:
                input_ids = input_ids.to(device)
                attention_mask = attention_mask.to(device)
                label = label.to(device)
                img = img.to(device)

                outputs = model(img, input_ids, attention_mask)
                loss = criterion(outputs, label)

                val_loss += loss.item() * img.size(0)
                preds = torch.argmax(outputs, dim=1)
                correct += torch.sum(preds == label)

        val_loss /= len(val_loader.dataset)
        accuracy = correct.double() / len(val_loader.dataset)

        scheduler.step(val_loss)

        print(
            f"Epoch {epoch+1}/{num_epochs} | "
            f"Train Loss: {train_loss:.4f} | "
            f"Val Loss: {val_loss:.4f} | "
            f"Val Acc: {accuracy:.4f}"
        )

        early_stopping(val_loss)
        if early_stopping.early_stop:
            print("Early stopping triggered. Stopping training.")
            break

train_model(
    model,
    train_loader,
    val_loader,
    criterion,
    optimizer,
    scheduler,
    num_epochs
)

import matplotlib.pyplot as plt

train_losses = [
    1.7920, 1.7779, 1.7894, 1.7918, 1.7918, 1.7918, 1.7918
]

val_losses = [
    1.7869, 1.7473, 1.7918, 1.7918, 1.7918, 1.7918, 1.7918
]

epochs = range(1, len(train_losses) + 1)

plt.figure(figsize=(6,4))
plt.plot(epochs, train_losses, marker='o', color='blue', label='Training Loss')
plt.plot(epochs, val_losses, marker='o', color='red', label='Validation Loss')

plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

val_accuracy = [
    0.5492, 0.5492, 0.5451, 0.5451, 0.5451, 0.5451, 0.5451
]

plt.figure(figsize=(6,4))
plt.plot(epochs, val_accuracy, marker='o', color='green')

plt.xlabel("Epoch")
plt.ylabel("Validation Accuracy")
plt.title("Validation Accuracy Across Epochs")
plt.grid(True)
plt.tight_layout()
plt.show()

import torch
import numpy as np
from sklearn.metrics import precision_score, recall_score
import torch.nn as nn

model = model.to(device)

def evaluate_model(model, test_loader, criterion):
    model.eval()

    correct_preds = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for input_ids, attention_mask, label, img in test_loader:
            input_ids = input_ids.to(device)
            attention_mask = attention_mask.to(device)
            label = label.to(device)
            img = img.to(device)

            outputs = model(img, input_ids, attention_mask)

            loss = criterion(outputs, label)
            _, preds = torch.max(outputs, dim=1)

            correct_preds += torch.sum(preds == label)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(label.cpu().numpy())

    accuracy = (correct_preds.double() / len(test_loader.dataset)).item()
    precision = precision_score(all_labels, all_preds, average="weighted", zero_division=0)
    recall = recall_score(all_labels, all_preds, average="weighted", zero_division=0)

    print("Test Accuracy:", accuracy)
    print("Precision:", precision)
    print("Recall:", recall)


evaluate_model(model, test_loader, criterion)

import matplotlib.pyplot as plt

metrics = ["Accuracy", "Precision", "Recall"]
values = [0.5491803278688525, 0.30159903251814035, 0.5491803278688525]

plt.figure(figsize=(6,4))
bars = plt.bar(metrics, values, color=["steelblue", "orange", "seagreen"])

plt.ylim(0, 1)
plt.ylabel("Score")
plt.title("Multimodal Model Performance on Test Set")

for bar in bars:
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width()/2,
        height + 0.02,
        f"{height:.2f}",
        ha="center",
        fontsize=10
    )

plt.grid(axis="y", linestyle="--", alpha=0.6)
plt.tight_layout()
plt.show()

class BERTResNetClassifier(nn.Module):
    def __init__(self, num_classes=6):
        super(BERTResNetClassifier, self).__init__()
        self.num_classes = num_classes
        # Image processing (ResNet)
        self.image_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)
        # Image processing (Fully Connected Layer)
        self.fc_image = nn.Linear(in_features=1000, out_features=num_classes, bias=True)
        self.drop = nn.Dropout(p=0.3)
        # Text processing (using the 768-dimensional BERT arrays)
        self.text_model = BertModel.from_pretrained("bert-base-uncased")
        # Text processing (Fully Connected Layer)
        self.fc_text = nn.Linear(in_features=self.text_model.config.hidden_size, out_features=num_classes, bias=True)
        # Fusion and classification
        self.softmax = nn.Softmax(dim=1)
    def forward(self, image, text_input_ids, text_attention_mask,):
        x_img = self.image_model(image)
        x_img = self.drop(x_img)
        x_img = self.fc_image(x_img)
        # Text branch
        x_text_last_hidden_states = self.text_model(
            input_ids = text_input_ids,
            attention_mask = text_attention_mask,
            return_dict=False
        )
        x_text_pooled_output = x_text_last_hidden_states[0][:, 0, :]
        x_text = self.drop(x_text_pooled_output)
        x_text = self.fc_text(x_text_pooled_output)
        x = torch.max(x_text, x_img)

        return x

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = BERTResNetClassifier(num_classes=6)
model= model.to(device)

criterion = nn.CrossEntropyLoss(weight=class_weights)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)
scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, min_lr=1e-6, factor=0.5, patience=1,)
num_epochs = 20

train_model(model, train_loader,val_loader, criterion, optimizer, scheduler, num_epochs)
#print("\n")
evaluate_model(model, test_loader, criterion)

val_accuracy = [
    0.5041, 0.6639, 0.6311, 0.6967,
    0.6885, 0.6721, 0.6926, 0.6967
]

plt.figure(figsize=(6,4))
plt.plot(epochs, val_accuracy, marker="o", color="seagreen")

plt.xlabel("Epoch")
plt.ylabel("Validation Accuracy")
plt.title("Validation Accuracy Across Epochs")
plt.grid(True)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
metrics = ["Accuracy", "Precision", "Recall"]
values = [
    0.7254098360655739,
    0.7211774598152942,
    0.7254098360655737
]

colors = ["steelblue", "darkorange", "forestgreen"]

plt.figure(figsize=(6, 4))
bars = plt.bar(metrics, values, color=colors)

plt.ylim(0, 1)
plt.ylabel("Score")
plt.title("Multimodal Model Performance on Test Set")

for bar in bars:
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        height + 0.02,
        f"{height:.2f}",
        ha="center",
        fontsize=10
    )

plt.grid(axis="y", linestyle="--", alpha=0.6)
plt.tight_layout()
plt.show()